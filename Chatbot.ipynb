{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Luh_YnFV3R6a",
        "aKnQOPeGGyri",
        "hieRKkhbFLvK",
        "VNHpOlrTFQuQ",
        "xnMy_6A7FW1t",
        "bo7yzm-UFbiY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luh_YnFV3R6a"
      },
      "source": [
        "# **General Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N-GpbfO3KLh"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import json\n",
        "import nltk as nltk\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from collections import Counter\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow_datasets as tfds\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdP3gQu33XAJ"
      },
      "source": [
        "# **Script to Organize Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXs-uug8SA8o"
      },
      "source": [
        "def get_entitie(state, entities_tracking):\n",
        "  total = list(state['slot_values'].keys())\n",
        "  if total is not None:\n",
        "    return [x for x in total if x not in entities_tracking]\n",
        "  else:\n",
        "    return []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq9EDlADAyvu"
      },
      "source": [
        "def get_info(turn, entities_tracking):\n",
        "  for frame in turn['frames']:\n",
        "    if frame['service'] == 'hotel':\n",
        "      return {\n",
        "        'entities': get_entitie(frame['state'], entities_tracking),\n",
        "        'intent': frame['state']['active_intent']\n",
        "      }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0BGG9cryCnv"
      },
      "source": [
        "def get_system_slots(turn):\n",
        "  slots = []\n",
        "  for frame in turn['frames']:\n",
        "    if frame['service'] == 'hotel':\n",
        "      for index in frame['slots']:\n",
        "        slots.append(index['slot'])\n",
        "  return slots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLxrMCez2CIn"
      },
      "source": [
        "def data(dialog_data):\n",
        "  extracted_info = []\n",
        "  for index in range(0, len(dialog_data['services'])):\n",
        "    if 'hotel' in dialog_data['services'][index]:\n",
        "      entities_tracking = []\n",
        "      for turn in dialog_data['turns'][index]:\n",
        "        if turn['speaker'] == 'USER':\n",
        "          info = get_info(turn, entities_tracking)\n",
        "          extracted_info.append({\n",
        "              'document': turn['utterance'],\n",
        "              'entities': info['entities'],\n",
        "              'intent': info['intent']\n",
        "          })\n",
        "          entities_tracking = (entities_tracking + list(set(info['entities']) - set(entities_tracking)))\n",
        "        else:\n",
        "          slots = get_system_slots(turn)\n",
        "          entities_tracking = (entities_tracking + list(set(slots) - set(entities_tracking)))\n",
        "  return extracted_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttzY5nqiBr5D"
      },
      "source": [
        "def get_entities(turn):\n",
        "  for frame in turn['frames']:\n",
        "    if frame['service'] == 'hotel':\n",
        "      return frame['state']['slot_values']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tADdXSh19jmX"
      },
      "source": [
        "def entities_dict(dialogs_data):\n",
        "  entities = {}\n",
        "  for dialog_data in dialogs_data:\n",
        "    for index in range(0, len(dialog_data['services'])):\n",
        "      if 'hotel' in dialog_data['services'][index]:\n",
        "        last_user_turn = dialog_data['turns'][index][-1]\n",
        "        if last_user_turn['speaker'] != 'USER':\n",
        "          last_user_turn = dialog_data['turns'][index][-2]\n",
        "        turn_entities = get_entities(last_user_turn)\n",
        "        for entitie in turn_entities:\n",
        "          words = turn_entities[entitie]\n",
        "          for word in words:\n",
        "            if not word in entities:\n",
        "              entities[word] = entitie\n",
        "  return entities\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDVd1SyyJiMq"
      },
      "source": [
        "dialogs = []\n",
        "for i in range(1,17):\n",
        "  if i < 10:\n",
        "    dialogs.append(pd.read_json(\"https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_00\" + str(i) + \".json\",encoding = \"ISO-8859-1\"))\n",
        "  else:\n",
        "    dialogs.append(pd.read_json(\"https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_0\" + str(i) + \".json\",encoding = \"ISO-8859-1\"))\n",
        "final_data = list(map(data, dialogs))\n",
        "test_dialogs = []\n",
        "test_dialogs.append(pd.read_json(\"https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/test/dialogues_001.json\", encoding = \"ISO-8859-1\"))\n",
        "test_dialogs.append(pd.read_json(\"https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/test/dialogues_002.json\", encoding = \"ISO-8859-1\"))\n",
        "test_data = list(map(data, test_dialogs))\n",
        "entidades = entities_dict(dialogs)\n",
        "#with open('entities.csv', 'w', newline='') as csvfile:\n",
        "#    fieldnames = ['word', 'entitie']\n",
        "#    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "#    writer.writeheader()\n",
        "#    for word in entidades:\n",
        "#      writer.writerow({'word': word, 'entitie': entidades[word]})\n",
        "#with open('final_data.csv', 'w') as f:\n",
        "#    w = csv.DictWriter(f, final_data[0][0].keys())\n",
        "#    w.writeheader()\n",
        "#    for dialogs in final_data:\n",
        "#      for dialog in dialogs:\n",
        "#        w.writerow(dialog))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnn59BAn3ya4"
      },
      "source": [
        "# **Importing and Processing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O1e3yMu_JGE"
      },
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/Acesarsilva/Chatbot_for_Hotel_Service/main/final_data.csv\",encoding = \"ISO-8859-1\")\n",
        "entity_map = pd.read_csv(\"https://raw.githubusercontent.com/Acesarsilva/Chatbot_for_Hotel_Service/main/entities.csv\",encoding = \"ISO-8859-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "yTpyRRkZBqO8",
        "outputId": "94b8f2d2-afd4-478c-b266-0c545e86933b"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>entities</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i need a place to dine in the center thats exp...</td>\n",
              "      <td>[]</td>\n",
              "      <td>find_hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Any sort of food would be fine, as long as it ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>find_hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sounds good, could I get that phone number? Al...</td>\n",
              "      <td>['hotel-pricerange', 'hotel-type']</td>\n",
              "      <td>find_hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes. Can you book it for me?</td>\n",
              "      <td>[]</td>\n",
              "      <td>find_hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i want to book it for 2 people and 2 nights st...</td>\n",
              "      <td>['hotel-bookday', 'hotel-bookpeople', 'hotel-b...</td>\n",
              "      <td>book_hotel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document  ...      intent\n",
              "0  i need a place to dine in the center thats exp...  ...  find_hotel\n",
              "1  Any sort of food would be fine, as long as it ...  ...  find_hotel\n",
              "2  Sounds good, could I get that phone number? Al...  ...  find_hotel\n",
              "3                       Yes. Can you book it for me?  ...  find_hotel\n",
              "4  i want to book it for 2 people and 2 nights st...  ...  book_hotel\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPp1NkccRZ52"
      },
      "source": [
        "encoded_dataset = dataset.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxhSQDyKRfYm"
      },
      "source": [
        "#Tratando tipo da coluna entities\n",
        "entities = []\n",
        "unique_entities = set()\n",
        "for x in encoded_dataset['entities']:\n",
        "  x = x.replace('[','')\n",
        "  x = x.replace(']','')\n",
        "  x = x.replace(\"'\", '')\n",
        "  x = x.replace(' ', '')\n",
        "  x = x.split(',')\n",
        "  entities.append(x)\n",
        "  for y in x:\n",
        "    unique_entities.add(y)\n",
        "encoded_dataset['entities'] = entities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPdRGx9FmSkG",
        "outputId": "19e1a599-d853-42d1-830f-e027c6e8ec33"
      },
      "source": [
        "#Lowercase\n",
        "encoded_dataset['document'] = encoded_dataset['document'].str.lower()\n",
        "punc_to_remove = string.punctuation\n",
        "\n",
        "#Removendo Pontuação\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('','', punc_to_remove))\n",
        "\n",
        "encoded_dataset['document'] = encoded_dataset['document'].apply(lambda text: remove_punctuation(text))\n",
        "\n",
        "#Removendo Stopwords\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS=set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopword(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "    \n",
        "encoded_dataset['document'] = encoded_dataset['document'].apply(lambda text: remove_stopword(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kab4xjLMtwiO"
      },
      "source": [
        "#Lemmatizando\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
        "def lemmatized_words(text):\n",
        "    pos_tagged_text = nltk.pos_tag(text.split())\n",
        "    return \" \".join([lemmatizer.lemmatize(word , wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
        "\n",
        "encoded_dataset['document'] = encoded_dataset['document'].apply(lambda text: lemmatized_words(text))\n",
        "encoded_dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e24iF_7iahDO"
      },
      "source": [
        "def encodeEntitities (entities_dict, entities_list):\n",
        "  for x in range(len(entities_list)):\n",
        "    entities_list[x] = entities_dict.get(entities_list[x])\n",
        "  return entities_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQMjIvlVHh8M"
      },
      "source": [
        "#Codificando Intents\n",
        "encoded_dataset['intent'] = LabelEncoder().fit_transform(encoded_dataset['intent'])\n",
        "#Codificando Entities\n",
        "unique_entities = list(unique_entities)\n",
        "encoded_entities = LabelEncoder().fit_transform(unique_entities)\n",
        "entities_dict = {unique_entities[x]:encoded_entities[x] for x in range(len(unique_entities))}\n",
        "encoded_dataset['entities'] = encoded_dataset['entities'].apply(lambda x: encodeEntitities(entities_dict, x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEDcDaYltgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2eac422-7291-48c3-bf93-86ab335d4d8e"
      },
      "source": [
        "#Criando nosso Vocabulário\n",
        "def addWords (vocabulary, word_list):\n",
        "  for x in word_list:\n",
        "    vocabulary.add(x)\n",
        "\n",
        "vocabulary = set()\n",
        "encoded_dataset['document'].apply(lambda text: addWords(vocabulary, text.split(\" \")))\n",
        "vocabulary = list(vocabulary)\n",
        "\n",
        "#Devemos Remover Números do Vocabulário ??????????????????????????\n",
        "\n",
        "tokens = LabelEncoder().fit_transform(vocabulary)\n",
        "tokens_dict = {vocabulary[x]:tokens[x] for x in range(len(vocabulary))}\n",
        "print(tokens_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'': 0, 'betcha': 506, 'hate': 1225, 'renting': 2081, 'repeat': 2082, 'regency': 2069, 'splendid': 2346, 'inspire': 1368, 'obvious': 1761, 'without': 2788, 'bonjour': 523, 'restauarnt': 2110, 'meh': 1596, 'cineworld': 673, 'break': 541, 'proper': 1980, 'goona': 1160, '1280': 73, 'arrving': 400, 'yougood': 2849, '2258': 144, 'hard': 1223, 'next': 1716, 'saigon': 2163, 'currently': 809, 'ell': 937, 'requirement': 2093, 'buildings': 558, 'fact': 1006, 'makes': 1561, 'goo': 1154, 'reccomend': 2042, 'jamaican': 1398, 'threestar': 2524, 'wasnt': 2730, 'want': 2724, 'otherwise': 1808, 'simply': 2271, 'highest': 1257, 'etc': 964, 'nee': 1701, 'arts': 403, 'best': 504, 'perfer': 1868, 'duration': 912, 'refried': 2065, 'spending': 2343, 'correcting': 771, 'cuisine': 806, 'weds': 2740, 'zizzi': 2863, 'chan': 626, 'moderate': 1644, 'locate': 1510, 'review': 2126, 'refuse': 2066, 'variety': 2691, 'joke': 1407, 'customer': 812, 'actual': 256, 'tyhat': 2647, 'consult': 755, 'bookit': 530, 'incorrect': 1344, 'cancel': 592, 'boss': 533, 'ideals': 1324, 'put': 1992, 'address': 262, 'dog': 888, 'kings': 1428, 'elsewhere': 939, 'mood': 1658, 'grateful': 1170, 'names': 1685, 'agian': 291, 'passage': 1844, 'mean': 1587, 'time': 2537, 'press': 1956, 'accommodating': 246, '6am': 205, 'j': 1396, 'ride': 2132, 'hows': 1304, 'shouldve': 2260, 'wouold': 2817, 'attraction': 431, '0730': 32, 'said': 2162, 'yeas': 2830, 'seoul': 2222, 'taxis': 2472, 'probably': 1975, 'train': 2609, 'greatand': 1172, 'singaporean': 2273, 'named': 1682, '115': 63, 'approximate': 375, 'maharajah': 1556, 'enjoy': 946, 'weeks': 2745, 'events': 970, 'many': 1568, 'k': 1414, 'seat': 2199, 'sister': 2276, 'mondaythan': 1655, 'nothats': 1750, 'suggestion': 2415, 'woah': 2791, 'kosher': 1435, 'workers': 2802, 'townthank': 2571, 'win': 2783, 'reread': 2095, 'destination': 850, 'western': 2754, 'huge': 1306, 'hakkacan': 1207, 'peterbourough': 1878, '1000': 47, 'distance': 879, 'concerthalls': 735, 'thankyou': 2494, 'camboats': 582, 'little': 1503, 'adjust': 267, 'cabs': 575, 'inquire': 1364, 'chicken': 649, 'theyll': 2511, 'hogwarts': 1271, 'done': 892, 'vegetarian': 2695, 'reviews': 2127, 'indonesian': 1352, 'think': 2516, 'finches': 1041, '0': 1, 'satruday': 2172, 'gxqzcbl8': 1201, 'change': 628, 'food': 1070, 'far': 1017, 'ian': 1318, 'archway': 384, 'grounds': 1180, 'youre': 2852, 'costly': 774, 'water': 2733, 'sortford': 2316, '1215': 69, 'mine': 1627, 'totally': 2558, 'tr8495': 2603, 'graffiti': 1168, 'afford': 280, 'allow': 317, 'waill': 2715, 'neeed': 1707, 'ghandi': 1137, 'cambride': 584, 'building': 557, 'highly': 1258, 'seen': 2213, 'tampa': 2463, 'tr0823': 2577, 'tr7057': 2598, 'slots': 2290, 'teusday': 2485, 'settled': 2234, 'bad': 466, 'fully': 1106, 'records': 2054, 'leave': 1460, 'host': 1288, 'inconvenient': 1343, 'meeting': 1593, 'bridge': 544, 'tr1465': 2578, 'particluar': 1835, 'required': 2092, 'misread': 1635, 'tr0254': 2575, '529': 190, 'advise': 278, 'theaters': 2502, 'nearest': 1695, 'fees': 1030, 'thong': 2519, 'bay': 480, 'meet': 1592, 'avalonthat': 446, 'surrounding': 2433, '0445': 18, 'set': 2231, 'towncheap': 2567, 'venetian': 2697, 'hiking': 1259, 'solo': 2301, 'awhile': 455, 'job': 1404, 'tuesday': 2638, 'covers': 789, 'least': 1459, 'steak': 2388, 'helps': 1248, 'workswill': 2806, '511': 187, 'means': 1588, 'lucky': 1547, 'researching': 2099, '0515': 21, '845': 224, 'typo': 2654, 'situation': 2283, 'temporary': 2480, 'driving': 905, 'open': 1794, 'yeahim': 2827, 'keeps': 1418, 'yessiree': 2840, 'range': 2010, 'numberpostcode': 1755, 'pricing': 1967, 'yu': 2855, 'parkingthe': 1830, 'wandered': 2721, 'confusing': 747, 'taj': 2454, 'transportation': 2614, '400': 175, 'doe': 886, 'police': 1923, 'rigamarole': 2134, 'metwo': 1603, 'yesplease': 2839, 'hurry': 1314, 'thata': 2496, 'description': 843, 'likes': 1490, 'fun': 1107, '2400': 151, 'peopl': 1857, 'and2': 346, 'tai': 2453, 'honestly': 1279, 'expensive': 994, 'alot': 325, 'reach': 2029, 'bishop': 512, 'colege': 706, 'focus': 1064, 'weve': 2757, 'need': 1702, 'tea': 2473, 'results': 2118, 'fez': 1034, 'broke': 551, 'necessarily': 1697, 'appreciated': 373, 'wfree': 2759, 'avaliable': 444, 'wow': 2818, 'shortening': 2255, 'sitting': 2281, 'wednedady': 2736, 'reserve': 2102, 'desperately': 849, 'ditton': 881, '615': 198, 'notice': 1752, 'whether': 2766, 'umm': 2662, 'expense': 993, 'r': 2003, 'involves': 1382, '430': 177, 'yu3moahh': 2856, 'park': 1827, 'legitimate': 1468, 'hours': 1299, 'whatever': 2761, 'person': 1873, 'als': 331, 'journey': 1409, 'maybe': 1583, 'pricerange': 1963, 'mention': 1598, 'naw': 1692, 'insanely': 1365, 'dishes': 876, 'arbury': 378, 'guests': 1197, 'someone': 2302, 'club': 696, 'cambridgeoh': 587, 'fairly': 1010, 'hungarian': 1310, 'impress': 1335, 'dodgy': 885, 'monday': 1654, 'total': 2557, 'towncan': 2566, 'ah': 294, 'breakfast': 543, 'frees': 1088, 'deal': 825, 'settle': 2233, 'rangefor': 2013, 'ranked': 2016, 'place': 1893, 'ya': 2822, 'reasonably': 2039, 'swear': 2435, 'vegan': 2694, 'hotell': 1293, 'travelling': 2621, 'ta': 2448, 'way': 2734, 'diner': 864, 'garden': 1118, 'favorites': 1023, 'basque': 479, 'sunday': 2422, 'liking': 1491, '10pm': 54, 'impartial': 1332, '1334': 79, 'danish': 816, '1534': 93, 'swedish': 2437, 'history': 1262, 'seem': 2211, '2': 124, 'lodging': 1517, 'cocum': 702, 'hungry': 1311, 'real': 2033, 'vehicle': 2696, 'gets': 1134, '800': 218, 'alright': 330, 'object': 1760, '1711': 103, 'alexander': 306, 'midsummer': 1620, 'pass': 1843, 'tenpin': 2481, 'door': 894, 'tree': 2625, 'anatolia': 345, 'starif': 2368, 'kambars': 1416, 'tr6034': 2591, 'al': 303, 'lime': 1492, '5days': 193, 'saurday': 2175, '1145': 62, 'recommendations': 2050, 'restaurant': 2111, 'hey': 1250, 'salon': 2167, 'hall': 1210, 'rating': 2021, 'umber': 2661, 'goodness': 1157, '50': 185, 'exhibition': 988, 'dining': 865, 'establishment': 962, 'willing': 2782, 'day': 822, 'steakhouse': 2389, 'public': 1987, 'station': 2380, 'postcard': 1941, '700': 208, 'hold': 1272, 'vinci': 2706, 'accommodations': 248, '15': 88, 'moderately': 1645, 'classy': 682, 'indeed': 1347, 'doesnt': 887, 'talk': 2460, 'waiting': 2717, 'lottery': 1536, 'finished': 1048, 'communte': 717, 'raise': 2007, 'arrive': 397, 'strover': 2407, 'wished': 2786, 'require': 2091, 'english': 945, 'williams': 2781, 'messing': 1601, 'viviting': 2710, 'cantonese': 594, 'treat': 2623, 'pleasant': 1906, 'tr5941': 2589, 'accomidate': 243, 'close': 689, 'fins': 1049, 'perfect': 1866, 'note': 1747, 'hut': 1316, 'aboutdo': 236, 'handled': 1214, 'help': 1240, '0615': 26, 'husband': 1315, 'cover': 787, 'length': 1471, 'moderatly': 1648, 'restaurants': 2113, 'kitchen': 1430, 'seei': 2206, 'inclusive': 1342, 'ring': 2136, 'collegerelated': 710, 'wednesdat': 2737, 'tell': 2478, 'referring': 2062, 'rangeexpensive': 2012, 'call': 578, 'lebanese': 1465, 'birmingham': 511, '0945': 42, 'huntington': 1313, 'necessary': 1698, 'hung': 1309, 'passengers': 1847, 'info': 1356, '2100': 133, 'stick': 2392, 'cotto': 778, 'astroturf': 421, 'reff': 2063, '1star': 123, 'falls': 1011, '1324': 77, 'galleries': 1114, 'andd': 347, 'already': 329, 'make': 1560, 'campus': 591, 'related': 2071, 'weekend': 2742, 'okey': 1779, 'glad': 1143, 'slum': 2292, 'funky': 1109, 'traveling': 2619, 'tr9493': 2605, 'arranging': 395, 'attend': 427, 'forget': 1076, 'christs': 666, 'christi': 664, 'oriental': 1804, 'seeking': 2210, '1010': 50, 'min': 1625, 'thought': 2522, 'past': 1848, 'anymore': 358, 'considered': 753, '0729': 31, 'interned': 1377, 'life': 1485, 'exploring': 999, 'artworks': 404, 'heads': 1231, 'carpool': 601, 'sold': 2300, 'ot': 1806, 'attractions': 432, 'express': 1000, 'group': 1181, 'cut': 813, 'centrally': 621, 'surely': 2430, 'phone': 1879, '1400': 83, 'soon': 2309, 'platform': 1903, 'midprice': 1617, 'fax': 1024, 'unrated': 2678, 'ratingcan': 2022, 'seats': 2201, 'running': 2157, 'kymmoy': 1436, 'twofer': 2645, 'advance': 273, 'transit': 2613, 'companion': 720, 'decently': 829, 'fee': 1027, 'choices': 657, 'charlie': 635, '215': 138, 'alysebray': 336, '1115': 57, 'picked': 1882, '330': 168, 'drive': 903, 'apreciate': 377, 'ticketsplease': 2532, '2215and': 141, 'telephone': 2477, 'trinity': 2628, 'heartbroken': 1236, 'noon': 1737, 'putting': 1993, 'aplhamilton': 366, 'rest': 2107, 'astropub': 420, 'muchthats': 1668, 'clsoe': 695, 'questions': 1999, 'tang': 2468, 'visiting': 2708, '939': 231, 'stamps': 2358, 'h': 1202, 'right': 2135, 'exhausted': 986, 'kambar': 1415, 'guess': 1185, 'peoplei': 1860, 'roles': 2143, 'specific': 2333, 'commuting': 719, 'concerns': 732, 'wifican': 2776, 'appears': 370, 'around': 391, '545': 192, 'clowns': 694, 'lkle': 1507, '1715': 104, 'peterborough': 1877, 'marys': 1573, 'gallery': 1115, 'yep': 2831, '5pm': 194, 'light': 1486, 'illl': 1330, 'different': 859, 'ggo': 1136, 'types': 2651, 'portuguese': 1933, 'saturdayplease': 2174, 'new': 1714, 'itshould': 1392, 'anyway': 364, 'ethiopian': 965, '0930': 41, 'excited': 982, 'scott': 2190, 'nusha': 1757, 'lookingfor': 1529, 'houses': 1301, 'itthank': 1393, 'afresh': 284, 'commit': 716, 'barbeque': 474, 'used': 2685, '0800': 34, 'greetings': 1177, 'airplane': 301, 'nicer': 1719, '300': 162, 'provide': 1983, 'oh': 1772, 'hidden': 1252, 'original': 1805, 'start': 2372, 'finally': 1040, '7': 207, 'sweet': 2438, 'scatter': 2183, 'east': 918, 'unable': 2665, 'gonna': 1152, 'nushas': 1758, 'kill': 1423, 'beds': 490, 'via': 2701, 'picks': 1884, 'parkin': 1828, 'friends': 1095, 'tr7047': 2597, 'byard': 569, 'hote': 1291, 'longs': 1526, 'depature': 841, '0801': 35, 'tonightso': 2553, 'allrighty': 319, 'smh': 2295, 'reccomendation': 2043, 'shoes': 2248, 'sophisticated': 2312, 'nearby': 1694, 'regent': 2070, 'acorn': 251, 'schedule': 2185, 'arms': 390, 'noodle': 1736, 'aylesbray': 458, 'rosass': 2150, 'couple': 785, 'unavailable': 2666, 'worries': 2810, 'tp': 2573, 'necessity': 1699, 'lynne': 1552, 'uno': 2676, 'repeating': 2083, 'magdalene': 1554, 'told': 2548, 'starts': 2374, 'arrival': 396, 'wold': 2793, 'bedroom': 489, '1836': 114, '1600': 96, 'indecisive': 1346, 'desperate': 848, 'examples': 979, 'deserve': 844, 'christ': 663, '717': 211, 'morden': 1660, 'gastropub': 1123, 'lady': 1440, 'gotta': 1163, 'popular': 1929, 'zero': 2860, 'okaywell': 1778, 'size': 2285, 'snappy': 2297, 'modified': 1651, 'issue': 1387, 'home': 1277, 'deciding': 832, 'accomadations': 242, 'meant': 1589, 'exact': 977, 'miss': 1636, 'year': 2828, 'farewell': 1019, 'turkish': 2640, 'beach': 484, '2430': 153, 'preferably': 1951, 'post': 1938, 'hakka': 1206, 'gives': 1141, 'scottish': 2191, 'print': 1971, 'reasonable': 2038, 'apologize': 368, 'zerostar': 2861, '2115': 135, '2058': 132, 'handle': 1213, 'associated': 417, 'transporting': 2615, 'tech': 2474, 'even': 967, 'rolls': 2144, 'focused': 1065, 'onethank': 1789, 'oclock': 1764, 'changing': 631, 'gourmet': 1165, 'tel': 2476, 'coulc': 780, 'hour': 1298, 'pizzeria': 1892, 'stazione': 2387, 'eating': 926, 'child': 650, 'neighborhhood': 1708, 'refernce': 2060, 'know': 1432, 'approximately': 376, 'dj': 882, 'regarding': 2067, 'airport': 302, 'bummer': 559, '1015': 51, 'halls': 1211, 'similar': 2270, 'shorten': 2254, 'b4irjdnn': 461, 'chosen': 662, 'finecan': 1045, 'rocks': 2142, 'reservations': 2101, 'fantastic': 1016, 'bring': 546, 'toward': 2563, 'venue': 2698, 'answered': 352, 'pepole': 1863, 'tight': 2535, 'nolets': 1734, 'sooner': 2310, 'lastly': 1448, 'mimosa': 1624, 'conflicting': 743, 'dealing': 826, 'miscommunicated': 1633, 'pain': 1820, 'vary': 2693, 'inbetween': 1337, 'guessing': 1186, '9892': 233, 'londonengland': 1521, 'digressing': 862, 'half': 1209, 'ti': 2529, 'bbq': 482, 'wiukd': 2790, 'getaway': 1131, 'state': 2376, 'shiraz': 2247, 'brutish': 554, 'surprise': 2431, 'yhou': 2844, 'clean': 683, 'afraid': 283, 'trusday': 2633, 'cucina': 805, 'involving': 1383, 'stevenage': 2391, 'ton': 2551, '230': 145, 'tax': 2470, 'helpfulness': 1244, 'morning': 1661, 'schedules': 2186, 'stating': 2379, 'fitzwilliam': 1057, 'swimmoingpool': 2443, 'perceptive': 1865, '830': 223, '1317': 76, 'left': 1467, 'care': 596, 'exciting': 983, 'polar': 1922, 'allen': 313, 'suit': 2417, 'cn21en': 700, 'parking': 1829, 'postal': 1939, 'welcome': 2749, 'leicester': 1469, '4pm': 181, 'copper': 767, 'confused': 746, 'frame': 1085, 'wanted': 2725, 'restuarant': 2116, 'lowest': 1542, 'autumn': 439, 'stress': 2404, 'wandlebury': 2723, 'family': 1013, 'smoothly': 2296, 'idf': 1326, '1045': 53, 'catharines': 610, 'checked': 642, 'interested': 1373, 'spot': 2352, 'nightsthere': 1727, 'priced': 1962, 'passenger': 1846, 'depart': 835, 'come': 712, 'causeway': 612, 'interest': 1372, 'hm': 1265, 'offered': 1769, 'begin': 493, '0900': 39, 'collage': 707, 'hole': 1273, 'departing': 836, 'hello': 1239, 'art': 401, 'gonville': 1153, 'wrong': 2820, 'shorter': 2256, 'bishops': 513, 'tag': 2450, 'recap': 2041, 'verify': 2700, 'informing': 1361, 'easy': 923, 'spectrum': 2339, 'bye': 571, 'italian': 1388, 'reastaurant': 2040, 'supposed': 2426, 'attitude': 430, 'highclass': 1254, 'st': 2355, 'storford': 2398, 'saturday': 2173, 'amusement': 344, 'anythings': 362, 'chip': 654, 'fora': 1073, 'pleasethe': 1913, 'yor': 2847, 'ratingwith': 2025, 'dialogue': 856, 'another': 351, 'norwhich': 1745, 'please': 1907, 'bed': 487, 'increase': 1345, 'moment': 1653, 'fair': 1009, 'hamilton': 1212, 'ideally': 1323, 'ideas': 1325, 'strange': 2400, 'iin': 1328, 'eastern': 921, 'arthurian': 402, 'ranges': 2015, 'boook': 531, 'entrance': 952, 'bill': 509, 'true': 2631, 'wonderful': 2795, 'drinks': 902, 'zip': 2862, 'downtown': 900, 'tr6838': 2594, 'week': 2741, 'title': 2543, 'afterall': 287, 'palace': 1821, 'allenbell': 315, 'fibnei': 1036, '600': 197, 'goodbye': 1156, 'b': 460, '915': 228, 'leas': 1458, 'annoying': 350, 'booking': 528, 'staying': 2385, 'pathological': 1849, 'ut': 2688, '1615thank': 98, 'yesthat': 2841, 'accommodate': 245, 'acceptable': 239, 'wouls': 2816, 'name': 1681, 'crash': 792, '0400': 15, 'ago': 292, 'recommending': 2052, '2215': 140, 'physicians': 1880, 'parks': 1832, '1200': 66, 'better': 507, 'excursion': 984, 'tr1492': 2579, '0700': 29, 'feature': 1025, 'skimping': 2287, 'typethanks': 2652, '01223244955': 5, 'ever': 971, '1545': 95, '1121': 59, 'expecting': 992, 'costs': 775, 'beginning': 494, 'dig': 861, 'lensdield': 1472, 'ive': 1395, 'report': 2086, 'theie': 2506, '200': 125, 'tr2379': 2581, 'stortford': 2399, 'alone': 323, 'arcon': 385, 'thatk': 2498, 'vicinity': 2702, 'el': 936, 'math': 1578, 'desk': 847, 'choose': 658, 'wifi': 2775, 'maintenance': 1559, 'helpbye': 1241, '500': 186, 'tr5859': 2588, 'minimum': 1629, 'seafoodwill': 2195, '521': 189, 'rajmahal': 2009, 'needing': 1704, '4stars': 183, 'excuse': 985, 'rich': 2131, 'contacted': 757, 'alyesbray': 335, 'diffidently': 860, 'stated': 2377, 'fit': 1053, 'town': 2565, 'fror': 1101, 'alkso': 312, 'critical': 799, 'oneplease': 1786, 'cityroomz': 676, 'yay': 2824, 'pleaseparking': 1911, 'aylesbury': 459, '1245': 71, 'sentence': 2221, 'stars': 2370, 'lied': 1483, 'actually': 257, 'include': 1338, 'nothat': 1749, '34': 169, 'condition': 736, 'carefully': 597, '11': 55, 'yescan': 2835, 'conformation': 744, 'pleasel': 1910, 'couldnt': 782, 'double': 896, 'ok': 1774, 'noi': 1731, 'jiggy': 1402, 'speaking': 2328, 'pipasha': 1888, 'specifics': 2336, 'else': 938, 'connect': 749, 'squalour': 2353, 'road': 2140, 'well': 2750, 'skimp': 2286, 'exotic': 990, 'concert': 733, 'namedrosas': 1683, '120': 65, 'mistaken': 1641, 'starsplease': 2371, 'lot': 1535, 'russian': 2158, 'five': 1058, 'whhat': 2767, 'try': 2635, 'manage': 1566, 'goes': 1147, 'low': 1540, 'fave': 1021, 'frankie': 1086, 'guesthoise': 1188, 'maximum': 1581, 'cross': 800, 'checkin': 643, 'nightclub': 1722, 'clarifying': 680, 'worth': 2812, 'eight': 934, 'everyone': 974, 'cb12ew': 613, 'awsome': 456, 'nope': 1738, 'longer': 1525, 'ahhh': 296, 'besides': 503, 'features': 1026, 'inform': 1358, 'driing': 901, 'nightsstarting': 1726, 'alexeander': 308, 'whenever': 2764, 'peple': 1862, 'welli': 2751, 'unfortunate': 2668, 'move': 1666, 'taxi': 2471, 'central': 620, 'fusion': 1110, 'ideal': 1322, 'insist': 1366, 'ref': 2057, 'mickey': 1608, 'anywhere': 365, 'complimentary': 727, 'sat': 2170, 'tues': 2637, 'old': 1781, 'church': 667, 'wild': 2779, 'guest': 1187, 'aroundi': 392, 'successful': 2410, 'depends': 842, 'universities': 2670, 'yummy': 2857, 'case': 603, 'self': 2215, 'avaion': 443, 'tr6954': 2595, 'dropped': 907, 'fridya': 1092, 'fore': 1074, '2020': 129, 'cash': 604, 'country': 783, 'nothing': 1751, 'arriving': 399, 'greek': 1175, 'om': 1783, 'preferences': 1953, 'allows': 318, 'ummmcan': 2664, 'house': 1300, 'centre': 622, 'bangkok': 470, 'plcae': 1905, 'fro': 1098, 'advice': 277, 'plan': 1898, 'cab': 573, 'persons': 1876, 't4ehqena': 2447, 'previous': 1958, 'strip': 2405, 'pity': 1890, 'starbucks': 2367, 'e': 913, 'rent': 2079, 'wish': 2785, 'lodege': 1515, 'operation': 1797, 'love': 1537, 'yesthats': 2842, 'craving': 793, 'ones': 1787, 'establishments': 963, 'select': 2214, 'korean': 1434, '1330': 78, 'onei': 1785, 'enemies': 944, 'lankan': 1444, 'offering': 1770, 'interests': 1375, 'reestaurant': 2056, 'closest': 692, 'proceed': 1977, 'college': 709, 'postcdode': 1942, 'tr7349': 2599, 'provided': 1984, '12': 64, 'getting': 1135, '1300': 74, 'da': 814, 'mercedes': 1600, '2000': 126, 'concerned': 731, 'mutliple': 1676, 'punting': 1990, 'company': 721, 'car': 595, 'feeling': 1029, 'roses': 2151, 'stayed': 2384, 'darrys': 818, 'possible': 1936, 'reply': 2085, 'alexanders': 307, 'tr6193': 2592, 'grabbing': 1167, 'remember': 2076, 'expect': 991, 'assistance': 415, 'packing': 1818, 'tips': 2541, 'small': 2293, 'wfii': 2758, '345': 170, 'wondering': 2798, 'look': 1527, 'stroll': 2406, 'school': 2187, 'part': 1834, 'two': 2644, 'section': 2203, 'funk': 1108, 'however': 1303, 'historical': 1261, 'hearing': 1234, 'particular': 1836, 'established': 961, 'locations': 1514, 'pricier': 1966, 'ticket': 2530, 'riverside': 2139, 'local': 1509, '6834': 204, 'whole': 2772, 'swimiming': 2440, 'listing': 1500, 'lol': 1519, 'guide': 1198, 'prive': 1974, 'aint': 299, 'yea': 2825, 'setting': 2232, 'thanksthats': 2493, 'mediterranean': 1590, 'lines': 1496, '1430': 85, 'huntingdon': 1312, 'taht': 2451, 'chop': 660, 'ratingwould': 2026, 'say': 2179, 'thurs': 2525, 'allenball': 314, 'eats': 927, 'ave': 447, 'dinner': 866, 'mind': 1626, 'pound': 1946, 'rangeplease': 2014, 'must': 1675, 'tourist': 2561, '74': 213, 'starving': 2375, 'general': 1127, 'okaydo': 1776, 'henever': 1249, 'reference': 2059, 'settles': 2235, '125': 72, 'mouse': 1665, 'complain': 723, 'afterwards': 289, 'adios': 265, 'suggestions': 2416, 'corn': 768, 'trail': 2608, 'worki': 2803, '0815': 36, 'abbey': 234, 'lower': 1541, 'familiar': 1012, 'rage': 2005, 'row': 2154, 'wonderfully': 2796, 'checking': 644, 'placed': 1895, 'headed': 1229, 'cambridge': 585, 'literally': 1502, 'southern': 2323, 'high': 1253, 'return': 2123, 'representative': 2087, 'workcan': 2801, 'night': 1721, '18th': 116, 'au': 433, 'frugal': 1102, 'question': 1998, 'stuff': 2408, 'experience': 997, 'clare': 678, 'whats': 2763, 'instead': 1369, 'departures': 840, 'truly': 2632, 'cherry': 647, 'till': 2536, 'suffice': 2411, 'tired': 2542, '1745': 107, 'wherever': 2765, 'though': 2521, 'thin': 2513, 'nirala': 1729, 'apologies': 367, 'inflexible': 1355, 'forgotten': 1078, 'jinling': 1403, 'kohinoor': 1433, 'lexus': 1480, 'wednesday': 2738, 'schools': 2188, 'standby': 2360, 'work': 2800, 'uber': 2655, 'dads': 815, 'disregard': 878, 'trainid': 2610, 'luch': 1545, 'rental': 2080, 'int': 1370, 'cool': 766, 'moroccan': 1662, 'odd': 1766, 'shopping': 2251, 'colleges': 711, 'hughes': 1307, 'happens': 1221, 'internet': 1378, 'separately': 2223, 'problem': 1976, 'absolutely': 237, 'antolia': 357, 'tandoori': 2466, 'confirmation': 742, 'speak': 2327, 'japanese': 1399, 'cambridgeshire': 588, 'ibiza': 1319, 'awesome': 452, 'property': 1982, 'form': 1079, 'suggest': 2413, 'fid': 1037, 'activities': 254, 'standsted': 2362, 'weekendsee': 2743, 'yet': 2843, 'riding': 2133, 'exchange': 981, 'hedges': 1238, 'scandinavian': 2182, 'retained': 2119, '0601': 25, 'informatin': 1359, 'zealand': 2859, 'conversation': 762, 'believe': 498, 'meghna': 1595, 'modern': 1650, '632': 200, 'month': 1657, 'guesthousehave': 1191, 'sounds': 2320, 'site': 2279, '1815': 111, 'tr6524': 2593, 'unsure': 2679, 'wed': 2735, 'rock': 2141, 'cuban': 804, 'celebrate': 616, 'trashy': 2616, 'typehotel': 2650, 'involve': 1381, 'green': 1176, '1730': 106, 'cambrige': 590, 'quest': 1997, 'pleaseif': 1909, 'end': 943, '8': 217, 'frustrating': 1103, 'needs': 1705, 'lovely': 1539, 'searching': 2198, 'indifferent': 1351, 'trying': 2636, 'relax': 2073, 'decided': 831, 'serving': 2229, 'uhm': 2659, 'lost': 1534, 'attempt': 426, 'staring': 2369, 'bites': 516, 'sort': 2315, 'ask': 410, 'choosing': 659, 'expensively': 995, 'satisfied': 2171, '810': 219, 'milton': 1623, 'minutes': 1632, 'area': 386, '824': 222, 'minute': 1631, 'special': 2329, 'fits': 1054, 'jello': 1400, '2245': 143, 'garbled': 1117, '1030': 52, 'bb': 481, 'desired': 846, 'preference': 1952, 'stratford': 2402, 'bennys': 501, 'mostly': 1663, '0245': 10, 'missed': 1637, 'olds': 1782, 'less': 1474, 'highend': 1255, 'sorts': 2317, 'asian': 408, 'addresses': 263, 'science': 2189, 'ty': 2646, 'stansted': 2364, 'usually': 2687, 'yescould': 2836, '1845': 115, 'barbecue': 473, 'figure': 1039, 'planned': 1900, 'much': 1667, 'hospital': 1286, 'reason': 2037, 'rated': 2018, '47': 180, 'condo': 737, 'tandoon': 2464, '1500': 89, 'occasion': 1763, 'suggestfor': 2414, 'cambridgeshould': 589, 'wast': 2731, 'tomorrow': 2550, 'boyfriend': 536, 'australasian': 436, '1415': 84, 'reservation': 2100, 'option': 1800, 'charges': 633, '1516': 91, '0100': 3, 'netflix': 1711, 'point': 1920, 'aslo': 413, 'onestar': 1788, 'sites': 2280, 'six': 2284, 'learner': 1457, '530': 191, 'lonely': 1523, 'stay': 2382, 'alpha': 326, 'tahtys': 2452, 'weill': 2747, 'friday': 1090, 'mall': 1564, 'areas': 388, 'addition': 260, '1900': 117, 'l': 1437, 'aww': 457, 'late': 1449, 'especially': 959, 'collect': 708, '1530': 92, 'telling': 2479, 'reccommend': 2044, 'festivals': 1033, 'cheapest': 639, 'politely': 1924, 'withouth': 2789, 'times': 2540, '1700': 102, 'rate': 2017, 'good': 1155, 'gueshouse': 1184, 'ids': 1327, 'cambrdige': 583, 'lodge': 1516, 'says': 2181, '2300': 146, 'ely': 940, 'suite': 2419, 'spicy': 2345, '1person': 122, 'hot': 1290, 'tr5507': 2586, 'latin': 1453, 'handling': 1215, 'nice': 1717, 'category': 609, '1539': 94, 'ahead': 295, 'optional': 1801, 'amount': 343, 'check': 641, '4': 174, 'listen': 1499, 'pocketbook': 1919, 'personal': 1874, 'cheers': 645, 'architecture': 383, 'archaeology': 380, 'prezzo': 1960, 'although': 333, 'groups': 1183, 'several': 2239, 'weelkend': 2746, 'caroline': 600, 'americas': 341, 'might': 1621, 'cityrooms': 675, 'laptop': 1445, 'mixed': 1643, 'connectivity': 751, 'er': 955, 'event': 969, 'youll': 2851, 'reversed': 2125, 'cost': 773, 'somewhat': 2307, 'lensfield': 1473, 'northside': 1744, 'placesneeds': 1897, 'rather': 2020, 'affordable': 281, 'order': 1803, 'hit': 1263, 'village': 2704, 'cambridgeim': 586, 'situated': 2282, 'musems': 1671, 'complete': 724, '745': 214, 'changed': 629, '1770': 109, 'boats': 522, 'shops': 2252, 'important': 1333, 'find': 1042, 'eastany': 919, 'sports': 2350, 'thank': 2489, 'riser': 2137, 'raiting': 2008, 'perimeters': 1870, 'theatre': 2503, 'hong': 1280, 'youthats': 2853, 'got': 1162, 'seven': 2237, 'yesits': 2837, '10': 45, 'destined': 852, 'backstreet': 465, 'lookng': 1530, '14': 81, 'queens': 1996, 'sweat': 2436, 'decide': 830, 'stages': 2357, 'hotel': 1292, '0845': 38, 'kinds': 1426, 'getme': 1133, 'ballare': 468, 'based': 476, 'nandos': 1686, 'gastropubs': 1124, 'dirty': 871, '2star': 157, 'enough': 948, 'cambidge': 581, 'bugged': 556, 'adjoining': 266, 'specializing': 2330, 'everybody': 973, 'catching': 608, 'information': 1360, '1620': 99, 'hoping': 1284, 'compare': 722, 'tonight': 2552, 'sporty': 2351, 'haha': 1204, 'pitch': 1889, 'slot': 2289, '29': 156, 'services': 2228, 'clifton': 688, 'theme': 2507, 'luck': 1546, 'indian': 1349, 'fan': 1014, 'adventurous': 275, '323': 166, 'seeid': 2207, '815not': 221, 'manager': 1567, 'fitzbillies': 1056, 'outside': 1811, 'typecontact': 2649, 'alike': 310, 'staya': 2383, 'priority': 1973, 'second': 2202, 'hanging': 1218, 'trains': 2611, 'shortly': 2259, 'daughter': 821, 'cetre': 625, 'prices': 1964, 'regardless': 2068, 'middlerange': 1614, 'able': 235, 'laiter': 1441, 'florida': 1061, 'swiss': 2444, 'every': 972, 'asked': 411, 'infor': 1357, 'moderatelypriced': 1646, 'trust': 2634, 'consider': 752, 'things': 2515, 'ashley': 407, 'took': 2555, '2330': 148, 'rad': 2004, 'bookedi': 527, 'tr9629': 2606, 'red': 2055, 'certain': 623, '36': 171, 'chesterton': 648, 'located': 1511, 'sock': 2299, 'volkswagen': 2711, 'alphaminon': 328, 'knew': 1431, 'numbers': 1756, 'space': 2325, 'purchase': 1991, 'wiki': 2778, 'street': 2403, 'looks': 1531, 'yup': 2858, 'pool': 1926, 'helpgoodbye': 1246, 'workthank': 2807, 'specials': 2331, 'african': 285, 'man': 1565, 'thats': 2500, 'connection': 750, 'yesbook': 2834, '1930': 119, 'basically': 478, 'lookup': 1532, 'refrence': 2064, 'belgian': 497, 'seems': 2212, 'silly': 2269, 'takeaway': 2456, 'cinema': 670, 'pickup': 1885, 'sitar': 2278, '7qvodjmi': 216, 'sightseeing': 2268, 'anthropology': 355, 'requests': 2090, 'extended': 1002, 'meets': 1594, 'cow': 790, '1116': 58, 'allthanks': 321, 'groovy': 1179, 'perhaps': 1869, 'typing': 2653, 'flexible': 1060, 'nightclubs': 1723, '2200': 139, 'ferret': 1032, 'avalon': 445, 'portrait': 1930, 'raza': 2028, 'mate': 1577, 'cabridge': 574, 'hmmmhow': 1268, 'friendly': 1094, 'free': 1087, 'lso': 1543, 'whoa': 2771, 'recoomend': 2053, 'british': 548, 'realize': 2034, 'youve': 2854, 'european': 966, 'ould': 1809, 'patience': 1850, 'luca': 1544, 'level': 1478, '6': 196, '2415': 152, 'direct': 867, 'oppss': 1799, 'adult': 271, 'contemporary': 759, 'sesame': 2230, 'ali': 309, 'pages': 1819, 'sri': 2354, 'planning': 1901, 'act': 252, 'rates': 2019, 'alimentum': 311, 'run': 2156, '2stars': 158, 'beside': 502, 'ext': 1001, 'fullest': 1105, 'sent': 2220, 'townplease': 2569, 'holel': 1274, 'restaurantis': 2112, 'including': 1341, 'favorite': 1022, 'aims': 298, 'dude': 910, 'stingy': 2394, 'opening': 1795, 'perfectly': 1867, 'avoid': 449, 'hotspot': 1297, 'howdy': 1302, 'cb8vvf4m': 615, 'intend': 1371, 'gone': 1151, 'prefer': 1949, 'punishment': 1988, 'michael': 1606, 'none': 1735, '3024': 163, 'poscode': 1934, 'days': 823, 'busting': 565, 'brady': 537, 'using': 2686, 'bood': 524, 'entertainment': 951, 'client': 686, 'woule': 2815, 'assisting': 416, 'wife': 2774, 'brassiere': 540, '909': 227, 'partner': 1839, 'wall': 2720, 'wets': 2756, 'hear': 1232, '1129': 60, 'primavera': 1969, 'arrangements': 394, 'theres': 2510, 'near': 1693, 'decent': 828, 'recommend': 2048, 'insists': 1367, 'austrian': 438, 'havent': 1227, 'send': 2218, 'international': 1376, 'celebrating': 617, 'reunion': 2124, 'didnt': 857, 'ratingis': 2023, 'kettles': 1420, 'epensive': 954, 'determine': 855, 'board': 519, 'travelers': 2618, 'nicest': 1720, 'read': 2030, 'match': 1574, 'junction': 1412, '0215': 8, 'stops': 2396, '415': 176, 'dollars': 891, 'addressthank': 264, 'de': 824, 'full': 1104, 'hopefully': 1283, '0415': 16, 'thee': 2505, 'making': 1562, 'glutton': 1145, 'wili': 2780, 'enter': 950, 'four': 1084, 'churchhill': 668, 'churchill': 669, 'discuss': 874, 'tours': 2562, 'theatres': 2504, '45': 179, 'handy': 1216, 'burden': 561, 'sir': 2275, 'leaving': 1464, 'hinton': 1260, 'suitable': 2418, 'concern': 730, 'thanks': 2491, 'mini': 1628, 'guesthouse': 1190, 'starting': 2373, 'museumand': 1673, 'asking': 412, 'fi': 1035, '0star': 43, 'explore': 998, 'towninfo': 2568, 'missing': 1638, 'yeslets': 2838, 'heading': 1230, 'north': 1740, 'hair': 1205, 'co': 701, 'ill': 1329, 'panasian': 1824, 'plese': 1916, 'alphamilton': 327, 'frills': 1096, 'warkworth': 2728, 'confidence': 740, 'eat': 924, 'quick': 2000, 'going': 1149, 'leverton': 1479, 'searched': 2197, '2045': 131, 'touch': 2559, 'specifcally': 2332, 'tr8431': 2602, 'matches': 1575, 'see': 2205, 'accomodations': 250, '1800': 110, 'tr5358': 2585, 'scratch': 2192, 'firstly': 1051, 'either': 935, 'plus': 1917, 'towns': 2570, '1915': 118, 'south': 2321, 'line': 1495, 'grab': 1166, 'correct': 770, 'margherita': 1569, 'egg': 932, 'restaruants': 2108, 'ugly': 2656, 'taken': 2457, 'salsa': 2168, 'accommodation': 247, 'let': 1475, 'children': 651, 'status': 2381, 'expensivemid': 996, 'lovell': 1538, 'arrives': 398, 'andgoodbye': 348, 'lammas': 1442, 'warkwoth': 2729, 'beautiful': 486, 'holy': 1276, 'convenient': 761, 'pizza': 1891, 'raves': 2027, 'shame': 2243, 'driver': 904, '1645': 101, 'southend': 2322, 'confirm': 741, 'yippee': 2845, 'play': 1904, 'persian': 1872, 'attactions': 425, 'froms': 1099, 'parts': 1840, 'awful': 453, 'tandoor': 2465, '2445': 154, '1': 44, '654': 202, 'doubt': 897, 'thorough': 2520, 'cheaply': 640, 'adc': 258, '100': 46, 'cookhouse': 765, 'today': 2544, 'beforewhat': 492, 'places': 1896, 'great': 1171, 'navigate': 1691, 'precise': 1948, 'admission': 268, 'remembered': 2077, 'staywhat': 2386, 'curious': 808, 'burger': 562, 'sisterinlaw': 2277, 'closeby': 690, 'nightlife': 1724, 'gas': 1121, 'clarify': 679, 'forth': 1080, 'route': 2153, 'shanghai': 2244, 'oddly': 1767, 'unfortunately': 2669, 'thas': 2495, 'available': 442, 'bar': 472, 'exhibit': 987, 'chat': 636, 'hmm': 1266, 'detailed': 853, 'receive': 2045, '0115': 4, 'allergies': 316, 'audi': 434, '24': 150, '445': 178, 'judgement': 1410, 'operating': 1796, 'eritrean': 957, 'still': 2393, 'availabe': 440, 'stop': 2395, 'specify': 2338, 'take': 2455, 'adults': 272, 'within': 2787, 'inexpensive': 1354, 'afternoon': 288, 'market': 1570, 'broughton': 552, 'basic': 477, 'process': 1978, 'tr5729': 2587, 'tickets': 2531, 'german': 1129, 'aid': 297, 'bedouin': 488, 'internetand': 1379, 'time1245': 2538, 'saints': 2165, 'northplease': 1743, 'spoil': 2348, 'gotten': 1164, 'earliest': 915, 'bet': 505, 'someplace': 2303, 'sussex': 2434, 'parents': 1826, 'uh': 2657, 'concerened': 729, 'arent': 389, 'pleasebook': 1908, 'todaygoodbye': 2545, 'walking': 2719, 'stevanage': 2390, 'halal': 1208, 'saying': 2180, 'really': 2036, 'serves': 2226, 'assist': 414, 'museums': 1674, 'learn': 1456, 'meal': 1585, '730': 212, 'helping': 1247, 'friend': 1093, 'happy': 1222, 'definitely': 833, 'convo': 764, '0300': 11, 'amenity': 339, 'permission': 1871, 'panahar': 1823, 'sala': 2166, 'sorrywas': 2314, 'pembroke': 1856, 'everything': 975, 'tr0755': 2576, 'unusual': 2680, 'money': 1656, 'thankful': 2490, 'fridaythank': 1091, 'shuttle': 2262, 'spend': 2342, 'afghan': 282, '900': 226, 'cristi': 797, 'terribly': 2483, 'heart': 1235, 'iam': 1317, 'search': 2196, 'bringing': 547, 'moderateprice': 1647, 'room': 2147, 'nevermind': 1713, 'listed': 1498, '0830': 37, '0545': 23, 'place4': 1894, 'wait': 2716, 'almost': 322, 'accomadation': 241, '140': 82, 'hmmm': 1267, 'golden': 1150, 'sense': 2219, 'overwhelming': 1815, 'accept': 238, 'guestroom': 1195, 'surei': 2429, 'specifically': 2334, 'portugese': 1932, 'emmanuel': 942, 'resaurant': 2097, 'star': 2366, 'shop': 2250, 'butthe': 566, 'code': 703, 'amazing': 337, 'guestrooms': 1196, 'vy': 2714, 'trip': 2629, 'ranged': 2011, 'million': 1622, 'sight': 2266, 'looking': 1528, 'excellent': 980, 'boos': 532, 'reserving': 2104, '30th': 164, 'early': 916, 'sport': 2349, 'obviously': 1762, 'bank': 471, 'requested': 2089, 'liar': 1481, 'okaythanks': 1777, 'leavers': 1462, 'short': 2253, 'others': 1807, 'tr9063': 2604, 'sum': 2421, 'gardens': 1120, 'johns': 1405, 'meals': 1586, 'catalan': 606, 'would': 2813, 'king': 1427, 'tr6982': 2596, 'namedthe': 1684, 'convinced': 763, 'hobsons': 1270, 'chose': 661, 'corpus': 769, 'upscale': 2682, 'liek': 1484, 'delicious': 834, '0530': 22, '2101': 134, '145': 87, '6pm': 206, 'years': 2829, 'isnt': 1386, '815': 220, 'guesthouses': 1192, 'safety': 2160, 'aware': 450, 'postcodes': 1945, 'cb4': 614, 'georgina': 1128, 'mexican': 1604, 'states': 2378, 'write': 2819, 'promising': 1979, 'wine': 2784, 'plans': 1902, 'give': 1139, 'side': 2264, '0645': 28, '33': 167, 'priiced': 1968, 'safe': 2159, 'interesting': 1374, 'fix': 1059, 'locating': 1512, 'inputting': 1363, 'retaurant': 2120, 'appealing': 369, 'belfy': 496, 'alert': 304, 'centr': 619, 'classical': 681, 'palce': 1822, 'thai': 2487, 'seeing': 2209, 'speed': 2340, 'thatll': 2499, 'malaysian': 1563, 'im': 1331, 'unless': 2672, '0915': 40, 'byart': 570, 'chance': 627, 'rooms': 2148, 'crossover': 802, 'oops': 1793, 'number': 1754, 'leincester': 1470, 'bell': 500, 'mistake': 1640, 'weirdo': 2748, 'hope': 1282, 'business': 564, 'everythingthanks': 976, 'sunrise': 2423, 'activity': 255, 'seventynine': 2238, 'romantic': 2146, '315': 165, 'australian': 437, 'stafford': 2356, 'anyone': 359, 'huh': 1308, 'towards': 2564, 'comes': 713, 'thanksi': 2492, 'likely': 1489, 'complex': 726, 'mysterious': 1677, '0745': 33, 'itll': 1391, 'shaddai': 2242, 'matter': 1579, 'works': 2805, 'nados': 1679, '655': 203, 'helpful': 1243, 'siagon': 2263, 'austalasian': 435, 'difference': 858, 'dolets': 890, 'sufficient': 2412, 'matching': 1576, 'met': 1602, '0600': 24, 'bunch': 560, 'possibly': 1937, 'fen': 1031, '1830': 112, 'clue': 698, 'groupon': 1182, 'particularly': 1837, 'cote': 776, 'create': 795, '4star': 182, '2011': 127, 'volunteer': 2712, 'prior': 1972, 'providing': 1986, 'spanish': 2326, 'postcode': 1943, 'efes': 931, 'sheeps': 2245, 'consist': 754, 'directly': 870, 'reader': 2031, '1315': 75, 'caribbean': 598, 'rice': 2130, 'pricey': 1965, 'chiquito': 655, 'planing': 1899, 'goodnight': 1158, 'needthanks': 1706, 'global': 1144, 'la': 1438, 'prince': 1970, 'broxbourne': 553, 'travels': 2622, 'ha': 1203, 'stanford': 2363, 'contact': 756, 'peoplecan': 1859, 'guesthousethat': 1193, 'nowhat': 1753, 'completed': 725, 'price': 1961, '715': 210, 'shift': 2246, 'advic': 276, 'boating': 521, 'add': 259, 'blessed': 517, 'cinemas': 671, 'smart': 2294, 'thatd': 2497, 'northend': 1741, 'travellers': 2620, 'toodles': 2554, 'brained': 538, 'northern': 1742, 'uhh': 2658, 'city': 674, 'jot': 1408, 'ratings': 2024, 'restrictions': 2115, 'nojust': 1732, 'beans': 485, '2130': 136, 'found': 1083, 'items': 1389, 'distracted': 880, 'recommended': 2051, 'peaceful': 1854, 'ned': 1700, 'latest': 1452, 'hi': 1251, 'style': 2409, 'properties': 1981, 'economy': 930, 'departure': 839, 'gastronomy': 1122, 'takes': 2458, '515': 188, 'midrange': 1618, 'kids': 1422, 'postalcode': 1940, 'preferable': 1950, 'concerthall': 734, '645': 201, 'live': 1504, 'type': 2648, 'india': 1348, 'snoring': 2298, 'corsica': 772, 'aiport': 300, 'amenities': 338, 'tremendously': 2627, 'ummm': 2663, 'agree': 293, 'kindly': 1425, 'holiday': 1275, 'curry': 810, 'eyes': 1005, 'criteria': 798, 'salsas': 2169, 'suites': 2420, 'arrange': 393, 'offers': 1771, 'email': 941, 'punter': 1989, 'reserved': 2103, 'destinations': 851, 'werent': 2752, 'tr6009': 2590, 'gain': 1112, '1515': 90, 'fifi': 1038, 'timeim': 2539, 'appropriate': 374, 'charging': 634, 'archeological': 381, 'foods': 1072, 'curiosity': 807, 'cheaper': 638, 'closet': 693, 'htel': 1305, 'twelve': 2643, 'continue': 760, 'shortest': 2257, 'get': 1130, 'covered': 788, 'land': 1443, 'unlucky': 2674, 'ontime': 1791, 'dear': 827, 'unplug': 2677, 'bee': 491, 'shabby': 2240, 'lets': 1476, 'doable': 883, 'trainthe': 2612, 'theater': 2501, 'believing': 499, 'certainly': 624, 'back': 463, 'discussed': 875, 'fot': 1082, 'wouldnt': 2814, 'availability': 441, 'serve': 2225, '0315': 12, 'world': 2808, 'midst': 1619, 'crossthe': 803, 'lunch': 1548, 'first': 1050, 'galleria': 1113, 'sells': 2217, 'meed': 1591, 'away': 451, 'personally': 1875, 'leaver': 1461, 'parkside': 1833, 'seriously': 2224, 'whipple': 2770, 'hasnt': 1224, 'nights': 1725, 'notes': 1748, 'vacation': 2689, 'luxury': 1550, 'feel': 1028, 'wonder': 2794, 'gosh': 1161, 'easier': 917, 'tr2286': 2580, 'eclectic': 928, 'peoples': 1861, 'poor': 1928, 'suredoes': 2428, 'marriot': 1571, 'todaythanks': 2546, 'date': 819, 'fare': 1018, 'marriott': 1572, 'may': 1582, 'buy': 567, 'boat': 520, '2x7en14': 159, 'afer': 279, 'wandlebery': 2722, 'scudamores': 2193, 'switching': 2445, 'enjoyed': 947, 'normal': 1739, 'offer': 1768, 'clunker': 699, 'bookings': 529, 'creative': 796, '921': 229, 'forward': 1081, 'main': 1557, 'response': 2106, 'three': 2523, 'peking': 1855, 'american': 340, 'anniversary': 349, 'cant': 593, 'technology': 2475, '0345': 14, 'clear': 684, 'varsity': 2692, 'calling': 580, 'matters': 1580, 'pasquale': 1842, 'picking': 1883, 'accomodate': 249, 'latter': 1454, 'brasserie': 539, 'among': 342, 'tr7802': 2600, 'barnabas': 475, 'bus': 563, 'exist': 989, 'youi': 2850, 'closer': 691, 'chines': 652, 'heard': 1233, 'cheap': 637, 'wi': 2773, '1721': 105, 'band': 469, 'aside': 409, 'yeah': 2826, 'worry': 2811, 'wonderfulthanks': 2797, 'remainder': 2075, 'entry': 953, 'tour': 2560, 'resaturant': 2096, 'assume': 418, '711': 209, 'charge': 632, '1345': 80, 'relatively': 2072, 'misspoke': 1639, 'ooked': 1792, 'sometime': 2305, 'lives': 1506, 'anything': 361, 'idea': 1321, 'inthe': 1380, 'sleep': 2288, 'botanic': 534, 'guesthous': 1189, '0430': 17, 'extra': 1003, 'dough': 898, 'super': 2424, 'quite': 2002, 'provides': 1985, 'package': 1817, 'ages': 290, 'long': 1524, 'unnamed': 2675, 'goig': 1148, 'clients': 687, 'october': 1765, 'limehouse': 1493, '0501': 20, 'relevant': 2074, 'hating': 1226, 'shadai': 2241, 'fast': 1020, 'doctors': 884, 'requirements': 2094, 'actaully': 253, 'quickly': 2001, 'coming': 715, 'scatterbrained': 2184, 'at1100': 422, 'mahal': 1555, 'save': 2176, 'wrongim': 2821, 'greatly': 1174, 'foe': 1066, 'mei': 1597, 'given': 1140, 'astray': 419, 'whale': 2760, 'irony': 1385, 'moon': 1659, 'chekc': 646, 'narrow': 1687, 'ohalrightwell': 1773, 'eastcan': 920, '5': 184, 'people': 1858, 'van': 2690, 'included': 1339, 'dope': 895, 'indoor': 1353, 'pieces': 1887, 'appointment': 371, '1130': 61, 'restauarant': 2109, 'whichever': 2768, 'could': 781, 'atleast': 423, 'helpfulthanks': 1245, 'jacuzzi': 1397, 'neighborhood': 1709, 'head': 1228, 'drop': 906, 'service': 2227, 'mumford': 1670, 'oak': 1759, 'kind': 1424, 'refer': 2058, 'alesbray': 305, 'west': 2753, 'sights': 2267, 'dont': 893, 'confusion': 748, 'economical': 929, 'westside': 2755, 'sound': 2319, 'realized': 2035, 'buzz': 568, '2030': 130, 'wanting': 2726, 'hotels': 1295, 'spice': 2344, 'us': 2683, 'paces': 1816, 'finding': 1043, 'directions': 869, 'mispoke': 1634, 'standard': 2359, 'hectic': 1237, 'adventure': 274, 'sure': 2427, 'dine': 863, 'direction': 868, 'answers': 353, 'pm': 1918, 'gethering': 1132, 'cozy': 791, 'mid': 1609, 'visits': 2709, 'therefore': 2508, 'archaelogy': 379, '0330': 13, '5star': 195, 'appreciate': 372, 'jesus': 1401, 'choice': 656, 'paying': 1853, 'hook': 1281, 'polynesian': 1925, 'breaker': 542, 'sorry': 2313, 'wants': 2727, 'shoot': 2249, 'seafood': 2194, '2015': 128, 'trouble': 2630, 'earlier': 914, 'strapped': 2401, 'request': 2088, 'cusine': 811, '2145': 137, 'southside': 2324, 'limit': 1494, 'rosas': 2149, 'disappointingthank': 872, 'parade': 1825, 'called': 579, 'duckling': 909, 'overwhelmed': 1814, 'clubs': 697, 'inn': 1362, 'due': 911, 'finethank': 1046, 'tommorow': 2549, 'cause': 611, 'details': 854, 'cottage': 777, 'hostel': 1289, 'nah': 1680, 'mainly': 1558, 'impossible': 1334, 'sometimes': 2306, 'hosons': 1285, 'nature': 1690, 'venues': 2699, 'laters': 1451, 'frm': 1097, 'n': 1678, 'resturant': 2117, '1630': 100, 'bit': 515, 'asap': 405, '1209': 68, 'retry': 2122, 'nasty': 1689, 'seated': 2200, 'use': 2684, 'tr5015': 2584, 'vue': 2713, 'upcoming': 2681, 'rethinking': 2121, 'parties': 1838, 'treating': 2624, 'thursday': 2526, '9': 225, 'keep': 1417, 'therell': 2509, 'antiques': 356, 'gandhi': 1116, 'wednsday': 2739, 'brilliant': 545, 'terms': 2482, 'theyre': 2512, '3star': 173, 'molecular': 1652, 'waitingdont': 2718, 'whateveryou': 2762, 'contacting': 758, 'visit': 2707, 'londons': 1522, 'thursdaycan': 2527, 'cafe': 576, 'fond': 1069, 'fish': 1052, 'referrence': 2061, 'midnightthis': 1616, 'stantsted': 2365, 'previously': 1959, '00': 2, 'gursthouse': 1199, 'never': 1712, 'somewhere': 2308, 'lodgings': 1518, 'departs': 837, 'tiger': 2534, 'foodie': 1071, 'thnks': 2518, 'romanian': 2145, 'splurge': 2347, 'clearly': 685, 'book': 525, 'hank': 1219, 'attending': 428, 'london': 1520, 'whilst': 2769, 'gardenia': 1119, 'soul': 2318, 'wifiparking': 2777, 'guten': 1200, 'average': 448, '1007': 49, 'preferred': 1954, 'made': 1553, 'one': 1784, 'comfortable': 714, 'forgot': 1077, 'liked': 1488, 'eastside': 922, 'talked': 2461, 'portraits': 1931, 'kirkwood': 1429, 'birds': 510, 'changes': 630, 'positive': 1935, 'tuesdaysunday': 2639, 'happen': 1220, 'hotelplease': 1294, 'opinion': 1798, 'um': 2660, 'options': 1802, 'riverboat': 2138, 'saw': 2178, 'worried': 2809, 'specified': 2337, 'soonest': 2311, 'together': 2547, 'lecester': 1466, 'cars': 602, 'recheck': 2047, 'always': 334, 'confuse': 745, 'helped': 1242, 'something': 2304, 'understand': 2667, 'computer': 728, 'county': 784, 'research': 2098, 'big': 508, 'like': 1487, 'thursdays': 2528, '3nights': 172, 'thaks': 2488, 'recommendation': 2049, 'along': 324, 'citys': 677, 'narrowing': 1688, 'tr8167': 2601, 'middle': 1612, '2315': 147, 'baba': 462, 'ashely': 406, 'folk': 1067, 'plenty': 1915, 'midday': 1611, '0715': 30, 'watch': 2732, '0500': 19, 'hospitals': 1287, 'saffron': 2161, 'wok': 2792, 'vin': 2705, 'ensure': 949, 'nil': 1728, 'leaves': 1463, 'ant': 354, 'motel': 1664, 'store': 2397, 'swimmingpool': 2442, 'du': 908, 'neither': 1710, 'eraina': 956, 'prepared': 1955, 'norwich': 1746, 'includes': 1340, 'mentioned': 1599, 'flying': 1062, 'hobson': 1269, 'pounds': 1947, 'michaelhouse': 1607, 'surprised': 2432, 'yesaddress': 2833, 'weekendthank': 2744, 'june': 1413, 'top': 2556, 'railway': 2006, 'lie': 1482, 'tr2694': 2583, 'commute': 718, 'impressive': 1336, 'mix': 1642, 'error': 958, 'yo': 2846, 'center': 618, '1945': 120, 'pleasure': 1914, 'bro': 550, 'system': 2446, 'midnight': 1615, 'est': 960, 'indication': 1350, 'list': 1497, 'follow': 1068, 'youd': 2848, 'single': 2274, 'postcodeaddress': 1944, 'meze': 1605, 'higher': 1256, 'forever': 1075, 'terrific': 2484, 'wont': 2799, 'thinking': 2517, 'midbudget': 1610, 'lasting': 1447, 'carolina': 599, 'coud': 779, 'also': 332, 'adress': 270, 'itthat': 1394, 'travel': 2617, 'seeim': 2208, 'reside': 2105, 'tremendous': 2626, '630': 199, 'unlikely': 2673, 'queen': 1995, 'townthe': 2572, 'revoir': 2128, 'tasca': 2469, 'honest': 1278, 'access': 240, 'security': 2204, 'fo': 1063, 'badso': 467, 'labelled': 1439, 'sell': 2216, 'swim': 2439, 'luncheon': 1549, 'taking': 2459, 'additional': 261, 'conf': 738, 'spellingcity': 2341, 'attached': 424, 'kettle': 1419, 'restraunt': 2114, 'ready': 2032, 'rez': 2129, 'evening': 968, 'grafton': 1169, 'eatery': 925, 'party': 1841, 'bbs': 483, 'fancy': 1015, 'budget': 555, '0130': 6, 'yard': 2823, 'passcode': 1845, '100300': 48, 'chinese': 653, 'outdoor': 1810, 'reminded': 2078, 'admissoin': 269, 'needed': 1703, 'bistro': 514, 'lettuce': 1477, 'royal': 2155, 'anytime': 363, '75': 215, 'backmaybe': 464, 'okay': 1775, 'conference': 739, 'french': 1089, 'lay': 1455, 'table': 2449, 'maybebut': 1584, 'caius': 577, 'jumping': 1411, 'talking': 2462, 'britishthemed': 549, 'factor': 1007, 'last': 1446, 'fine': 1044, 'saved': 2177, 'nicely': 1718, 'tuscan': 2642, 'castle': 605, 'desire': 845, 'fussy': 1111, 'university': 2671, 'kidding': 1421, 'fitting': 1055, 'online': 1790, 'show': 2261, 'recent': 2046, 'christmas': 665, 'moderite': 1649, 'finish': 1047, 'overnight': 1813, 'thing': 2514, 'losing': 1533, '0145': 7, 'shortford': 2258, 'gave': 1126, 'accomidations': 244, 'girton': 1138, '1445': 86, 'later': 1450, 'per': 1864, 'nobut': 1730, 'news': 1715, '930': 230, 'middleeastern': 1613, '1230': 70, 'alls': 320, 'track': 2607, 'pools': 1927, 'bother': 535, 'giving': 1142, 'eggrolls': 933, 'yes': 2832, 'points': 1921, 'tandorri': 2467, 'overbooked': 1812, '245': 155, 'extremely': 1004, 'belfry': 495, 'minus': 1630, 'gathering': 1125, 'guesthousetype': 1194, 'tr': 2574, 'cineme': 672, 'museum': 1672, '3': 160, 'bloomsbury': 518, '1750': 108, 'downing': 899, 'neat': 1696, 'go': 1146, 'goodplease': 1159, '945': 232, 'hk': 1264, 'dislike': 877, 'sidney': 2265, 'tiem': 2533, 'hotpot': 1296, 'pleases': 1912, 'vietnamese': 2703, 'listings': 1501, 'id': 1320, 'areait': 387, 'irish': 1384, 'discounts': 873, '0630': 27, 'nolet': 1733, 'pretty': 1957, 'crossing': 801, '1615': 97, 'location': 1513, 'working': 2804, '30': 161, 'crazy': 794, 'joint': 1406, 'pay': 1852, 'patient': 1851, '1834': 113, 'tr2534': 2582, 'booked': 526, 'hang': 1217, 'slug': 2291, 'attention': 429, 'fails': 1008, '0230': 9, 'liverpool': 1505, 'pick': 1881, 'greg': 1178, 'greater': 1173, 'catch': 607, '1100': 56, 'suppose': 2425, 'parkingthere': 1831, 'replied': 2084, 'round': 2152, 'swimming': 2441, 'aft': 286, 'codes': 704, 'anyplace': 360, 'dojo': 889, 'front': 1100, 'coffee': 705, 'since': 2272, 'picky': 1886, 'course': 786, '1jy': 121, 'awfulis': 454, 'dates': 820, 'quality': 1994, 'multiple': 1669, '2345': 149, 'turns': 2641, 'specifications': 2335, 'architectural': 382, 'exactly': 978, '1207': 67, 'loaded': 1508, 'okthanks': 1780, 'darn': 817, 'departung': 838, 'saint': 2164, '2230': 142, 'lynn': 1551, 'byebye': 572, 'th': 2486, 'itgoodbye': 1390, 'stands': 2361, 'settling': 2236}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnb2eTDSB42L"
      },
      "source": [
        "#Dividindo Conjunto de Dados\n",
        "extractor_X = encoded_dataset['document']\n",
        "extractor_y = encoded_dataset['entities']\n",
        "extractor_X_train, extractor_X_test, extractor_y_train, extractor_y_test = train_test_split(extractor_X, extractor_y, test_size=0.4, random_state=1)\n",
        "extractor_X_test, extractor_X_validation, extractor_y_test, extractor_y_validation = train_test_split(extractor_X_test, extractor_y_test, test_size=0.4, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8ExDeHX0YTl"
      },
      "source": [
        "VOCAB_SIZE = len(vocabulary)\n",
        "VECTOR_SIZE = 5\n",
        "BATCH_SIZE = 64\n",
        "INTERN_LAYER_SIZE = 60\n",
        "END_LAYER_SIZE = len(entities_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBW23iz-zrYU"
      },
      "source": [
        "# **Creating Entity Extractor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "72cEa2JOzzEU",
        "outputId": "d6559a22-3c5a-4845-d910-51910d81f2ad"
      },
      "source": [
        "entity_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>entitie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saturday</td>\n",
              "      <td>hotel-bookday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>hotel-bookpeople</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>university arms hotel</td>\n",
              "      <td>hotel-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>expensive</td>\n",
              "      <td>hotel-pricerange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hotel</td>\n",
              "      <td>hotel-type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>rosa's b ed and breakfast</td>\n",
              "      <td>hotel-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>a and be guest house</td>\n",
              "      <td>hotel-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>avolon</td>\n",
              "      <td>hotel-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>cambridge belgry</td>\n",
              "      <td>hotel-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>el shadai</td>\n",
              "      <td>hotel-name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          word           entitie\n",
              "0                     saturday     hotel-bookday\n",
              "1                            2  hotel-bookpeople\n",
              "2        university arms hotel        hotel-name\n",
              "3                    expensive  hotel-pricerange\n",
              "4                        hotel        hotel-type\n",
              "..                         ...               ...\n",
              "174  rosa's b ed and breakfast        hotel-name\n",
              "175       a and be guest house        hotel-name\n",
              "176                     avolon        hotel-name\n",
              "177           cambridge belgry        hotel-name\n",
              "178                  el shadai        hotel-name\n",
              "\n",
              "[179 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CkVdZoAzwhe"
      },
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    max_tokens = VOCAB_SIZE,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = VECTOR_SIZE)\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    VOCAB_SIZE,\n",
        "    BATCH_SIZE,\n",
        "    embeddings_initializer=\"uniform\",\n",
        "    embeddings_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    embeddings_constraint=None,\n",
        "    mask_zero=False,\n",
        "    input_length= VECTOR_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJwb2of29Uy_"
      },
      "source": [
        "def baseline_model(VOCAB_SIZE, VECTOR_SIZE, BATCH_SIZE, INTERN_LAYER_SIZE, END_LAYER_SIZE):\n",
        "  # Criando Camada de Vetorização\n",
        "    vectorize_layer = TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    max_tokens = VOCAB_SIZE,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = VECTOR_SIZE\n",
        "    )\n",
        "\n",
        "  # Criando Camada de Embedding\n",
        "    embedding_layer = tf.keras.layers.Embedding(\n",
        "    VOCAB_SIZE,\n",
        "    BATCH_SIZE,\n",
        "    embeddings_initializer=\"uniform\",\n",
        "    embeddings_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    embeddings_constraint=None,\n",
        "    mask_zero=False,\n",
        "    input_length= VECTOR_SIZE\n",
        "    )\n",
        "\n",
        "  # Montando Modelo\n",
        "    model = Sequential()\n",
        "    model.add(vectorize_layer)\n",
        "    model.add(embedding_layer)\n",
        "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True))),\n",
        "    \n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    model.add()#Adicionar Camada Convolucional\n",
        "    model.add(Dense(INTERN_LAYER_SIZE,activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(END_LAYER_SIZE, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIHRYGSR9ZtN"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(extractor_X_train, extractor_y_train, epochs=150, batch_size=32, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxXyHu14f8zJ"
      },
      "source": [
        "# **Creating Intent Classificator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWFzGLd9ingV"
      },
      "source": [
        "def encoding(intent, unique_intents):\n",
        "  encoding = [0 for x in unique_intents]\n",
        "  encoding[intent] = 1\n",
        "  #return ''.join(encoding)\n",
        "  return encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAGKvcoIgFMf"
      },
      "source": [
        "dt_intent = encoded_dataset.copy()\n",
        "dt_intent = dt_intent.drop(columns=['entities'])\n",
        "unique_intents = dt_intent['intent'].unique()\n",
        "dt_intent['intent'] = dt_intent['intent'].apply(lambda intent: encoding(intent, unique_intents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss_rhHXt_zJs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "46f82415-971d-4728-da23-06c4d8a8a538"
      },
      "source": [
        "data_train, data_test = train_test_split(dt_intent, test_size=0.4, random_state=1)\n",
        "data_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7336</th>\n",
              "      <td>dont need reservation time would like know pri...</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22989</th>\n",
              "      <td>great would like book table</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14280</th>\n",
              "      <td>traveling cambridge broxbourne</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8908</th>\n",
              "      <td>book 1 people 5 nights starting sunday</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24421</th>\n",
              "      <td>need place stay free wifi</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                document     intent\n",
              "7336   dont need reservation time would like know pri...  [0, 0, 1]\n",
              "22989                        great would like book table  [1, 0, 0]\n",
              "14280                     traveling cambridge broxbourne  [1, 0, 0]\n",
              "8908              book 1 people 5 nights starting sunday  [0, 1, 0]\n",
              "24421                          need place stay free wifi  [0, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUG1WzkzDU_O"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "intent_train = tf.data.Dataset.from_tensor_slices((data_train['document'], pad_sequences(list(data_train['intent']), 3)))\n",
        "intent_test = tf.data.Dataset.from_tensor_slices((data_test['document'], pad_sequences(list(data_test['intent']), 3)))\n",
        "\n",
        "intent_train = intent_train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "intent_test = intent_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXnOGIiZRQJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970e0d32-0187-42dc-ea87-1e26e54e97d5"
      },
      "source": [
        "for example, label in intent_train.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text:  [b'take anything free parking'\n",
            " b'sure please tell address phone number postcode'\n",
            " b'yes need hotel north close airport thanks'\n",
            " b'help find place stay maybe expensive guesthouse'\n",
            " b'thanks youre help may also address phone number restaurant'\n",
            " b'thats need thanks' b'5pm available instead'\n",
            " b'departing stevenage going cambridge'\n",
            " b'hello chinese restaurants centre'\n",
            " b'yes need reservation thursday 1630 4 people' b'thanks'\n",
            " b'need find hotel cambridge decent prices'\n",
            " b'would like star rating 4 cost matter would also like free parking'\n",
            " b'thats need right thanks help'\n",
            " b'yes also need train departs stevenage goes cambridge'\n",
            " b'want train leave 1630' b'needed help thank' b'west price range'\n",
            " b'would like travel saturday go leicester' b'looking place dine'\n",
            " b'near restaurant' b'yes group people monday 1715 please'\n",
            " b'center one good could provide room type hotel guesthouse address postcode well'\n",
            " b'alphamilton guest house still operation' b'price range'\n",
            " b'great thanks much help' b'free wifi' b'looking fitzbillies cambridge'\n",
            " b'thats okay looking hotel area restaurant please help'\n",
            " b'also need place stay would like hotel 3 star rating free parking'\n",
            " b'would like guesthouse'\n",
            " b'im craving spicy food find indian restaurant east end please'\n",
            " b'id like moderately priced hotel centre pool'\n",
            " b'make reservation monday 1930 8 people'\n",
            " b'im looking guesthouse stay dont care parking though'\n",
            " b'yes please would like 8 people 5 nights starting monday'\n",
            " b'hotel guesthouse 4 star range' b'entrance fee west part town'\n",
            " b'two people total' b'really need hotel parking isnt really issue us'\n",
            " b'well would like guesthouse dont internet'\n",
            " b'need moderately priced guesthouse' b'need free parking'\n",
            " b'great recommend one book 3 nights coming friday 2 party'\n",
            " b'yes may address postcode junction theatre' b'place north 2 star rating'\n",
            " b'need train tuesday goes london kings cross'\n",
            " b'diffidently want hotel ashley sounds good book stay thursday'\n",
            " b'suggest whale time need address entrance fee postcode'\n",
            " b'different hotel price range' b'guesthouse'\n",
            " b'needing leave hotel 1645 arrange'\n",
            " b'thanks much id also like find expensive restaurant center'\n",
            " b'yes also looking expensive restaurant serving english food'\n",
            " b'think thanks lot take care bye'\n",
            " b'would like find guesthouse stay thats expensive price range help'\n",
            " b'make 1 night' b'nice day'\n",
            " b'prezzo sounds good tell address postcode please'\n",
            " b'star rating guest house address phone number'\n",
            " b'nightclub get information'\n",
            " b'ill need go hotel museum id like leave 1900 please'\n",
            " b'want one moderate prices free wifi' b'dinner 5 people']\n",
            "label:  [[0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2RVVQm1-NUe"
      },
      "source": [
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(list(dt_intent['document']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYRb9wEf-_vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e778b61-a013-46e4-be5e-d4456336d55f"
      },
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'need', 'please', 'hotel', 'yes', 'like', 'thank',\n",
              "       'free', 'would', 'looking', 'book', 'also', 'people', 'nights',\n",
              "       'im', 'number', 'stay', 'help', 'place'], dtype='<U18')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_acGgYLG_S5B"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(3, activation = \"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_hLdgBN_rVm"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK_TZds4HGr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7473e9e3-7a80-41c2-df95-8f6765da17a0"
      },
      "source": [
        "print([layer.supports_masking for layer in model.layers])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, True, True, True, True, True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yXj504PARUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704c798e-ed2d-4022-8863-a4693c2e1649"
      },
      "source": [
        "history = model.fit(intent_train, epochs=35,\n",
        "                    validation_data=intent_test,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "252/252 [==============================] - 41s 83ms/step - loss: 0.9563 - accuracy: 0.5795 - val_loss: 0.7033 - val_accuracy: 0.7896\n",
            "Epoch 2/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.6027 - accuracy: 0.8073 - val_loss: 0.5542 - val_accuracy: 0.8078\n",
            "Epoch 3/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.5178 - accuracy: 0.8287 - val_loss: 0.5140 - val_accuracy: 0.8156\n",
            "Epoch 4/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.4802 - accuracy: 0.8387 - val_loss: 0.4960 - val_accuracy: 0.8281\n",
            "Epoch 5/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.4537 - accuracy: 0.8466 - val_loss: 0.4840 - val_accuracy: 0.8224\n",
            "Epoch 6/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.4363 - accuracy: 0.8524 - val_loss: 0.4781 - val_accuracy: 0.8281\n",
            "Epoch 7/35\n",
            "252/252 [==============================] - 17s 66ms/step - loss: 0.4228 - accuracy: 0.8560 - val_loss: 0.4747 - val_accuracy: 0.8318\n",
            "Epoch 8/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.4127 - accuracy: 0.8569 - val_loss: 0.4708 - val_accuracy: 0.8313\n",
            "Epoch 9/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.4055 - accuracy: 0.8608 - val_loss: 0.4706 - val_accuracy: 0.8276\n",
            "Epoch 10/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.3959 - accuracy: 0.8634 - val_loss: 0.4725 - val_accuracy: 0.8297\n",
            "Epoch 11/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3869 - accuracy: 0.8655 - val_loss: 0.4716 - val_accuracy: 0.8302\n",
            "Epoch 12/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.3793 - accuracy: 0.8689 - val_loss: 0.4740 - val_accuracy: 0.8281\n",
            "Epoch 13/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.3730 - accuracy: 0.8689 - val_loss: 0.4769 - val_accuracy: 0.8297\n",
            "Epoch 14/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3644 - accuracy: 0.8707 - val_loss: 0.4773 - val_accuracy: 0.8302\n",
            "Epoch 15/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3577 - accuracy: 0.8735 - val_loss: 0.4827 - val_accuracy: 0.8302\n",
            "Epoch 16/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3547 - accuracy: 0.8747 - val_loss: 0.4851 - val_accuracy: 0.8328\n",
            "Epoch 17/35\n",
            "252/252 [==============================] - 16s 63ms/step - loss: 0.3513 - accuracy: 0.8768 - val_loss: 0.4879 - val_accuracy: 0.8286\n",
            "Epoch 18/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.3469 - accuracy: 0.8778 - val_loss: 0.4901 - val_accuracy: 0.8281\n",
            "Epoch 19/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.3426 - accuracy: 0.8776 - val_loss: 0.5045 - val_accuracy: 0.8266\n",
            "Epoch 20/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3397 - accuracy: 0.8821 - val_loss: 0.5033 - val_accuracy: 0.8286\n",
            "Epoch 21/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3379 - accuracy: 0.8822 - val_loss: 0.5071 - val_accuracy: 0.8271\n",
            "Epoch 22/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3331 - accuracy: 0.8826 - val_loss: 0.5103 - val_accuracy: 0.8234\n",
            "Epoch 23/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3282 - accuracy: 0.8849 - val_loss: 0.5183 - val_accuracy: 0.8260\n",
            "Epoch 24/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3249 - accuracy: 0.8848 - val_loss: 0.5189 - val_accuracy: 0.8234\n",
            "Epoch 25/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3223 - accuracy: 0.8849 - val_loss: 0.5284 - val_accuracy: 0.8224\n",
            "Epoch 26/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3188 - accuracy: 0.8875 - val_loss: 0.5317 - val_accuracy: 0.8193\n",
            "Epoch 27/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3185 - accuracy: 0.8869 - val_loss: 0.5427 - val_accuracy: 0.8167\n",
            "Epoch 28/35\n",
            "252/252 [==============================] - 17s 69ms/step - loss: 0.3140 - accuracy: 0.8880 - val_loss: 0.5375 - val_accuracy: 0.8219\n",
            "Epoch 29/35\n",
            "252/252 [==============================] - 16s 65ms/step - loss: 0.3101 - accuracy: 0.8881 - val_loss: 0.5414 - val_accuracy: 0.8203\n",
            "Epoch 30/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3113 - accuracy: 0.8891 - val_loss: 0.5593 - val_accuracy: 0.8234\n",
            "Epoch 31/35\n",
            "252/252 [==============================] - 16s 63ms/step - loss: 0.3059 - accuracy: 0.8916 - val_loss: 0.5591 - val_accuracy: 0.8193\n",
            "Epoch 32/35\n",
            "252/252 [==============================] - 16s 64ms/step - loss: 0.3039 - accuracy: 0.8934 - val_loss: 0.5639 - val_accuracy: 0.8167\n",
            "Epoch 33/35\n",
            "252/252 [==============================] - 16s 63ms/step - loss: 0.3035 - accuracy: 0.8920 - val_loss: 0.5663 - val_accuracy: 0.8182\n",
            "Epoch 34/35\n",
            "252/252 [==============================] - 16s 63ms/step - loss: 0.2990 - accuracy: 0.8944 - val_loss: 0.5767 - val_accuracy: 0.8167\n",
            "Epoch 35/35\n",
            "252/252 [==============================] - 16s 63ms/step - loss: 0.2975 - accuracy: 0.8944 - val_loss: 0.5748 - val_accuracy: 0.8177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boM-aYIdAaRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b319e0c7-f0a8-4ac6-f13d-f4d1eb227c80"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(intent_test)\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "168/168 [==============================] - 3s 16ms/step - loss: 0.5826 - accuracy: 0.8210\n",
            "Test Loss: 0.5826109647750854\n",
            "Test Accuracy: 0.8209525346755981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erh2FchEo38p"
      },
      "source": [
        "# **Tunning Intent Classificator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N04HNRAIo81X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3e01EtN4mZE"
      },
      "source": [
        "# **Luan Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4czRBktRZm0w"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ7Ygc5VkqGX"
      },
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "texts = []\n",
        "training_data = []\n",
        "testing_data = []\n",
        "for dialogs in final_data:\n",
        "  for dialog in dialogs:\n",
        "    texts.append(dialog['document'])\n",
        "    training_data.append(dialog)\n",
        "for dialogs in test_data:\n",
        "  for dialog in dialogs:\n",
        "    texts.append(dialog['document'])\n",
        "    testing_data.append(dialog)\n",
        "training = np.array(training_data)\n",
        "testing = np.array(testing_data)\n",
        "encoder.adapt(texts)\n",
        "vocab = np.array(encoder.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45SlZvibofX0"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvC-mibgo_93"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v62Lckb-pOoy"
      },
      "source": [
        "history = model.fit(training, epochs=10,\n",
        "                    validation_data=testing,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpmX0ujhsG_t"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKnQOPeGGyri"
      },
      "source": [
        "## **Imports e Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgpS2-FXG08_"
      },
      "source": [
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hieRKkhbFLvK"
      },
      "source": [
        "## **Pré-Processamento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNHpOlrTFQuQ"
      },
      "source": [
        "### **Ajustes no Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnMy_6A7FW1t"
      },
      "source": [
        "### **Tokenização**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo7yzm-UFbiY"
      },
      "source": [
        "### **Criação de Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6N4cv84FemB"
      },
      "source": [
        ""
      ]
    }
  ]
}